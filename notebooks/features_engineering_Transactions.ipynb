{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a9d0ca-71f1-40ca-81ab-2c51c978e6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tous les fichiers CSV nettoyes ont été chargés avec succès !\n"
     ]
    }
   ],
   "source": [
    "#Detection fraude - Feature engineering (l'objectif est d'extraire les caracteristiques pertinentes a partir des donnees netoyees, en vue de detecter les fraudes liee aux transactions)\n",
    "\n",
    "#1) importation des bibliotheques\n",
    "import pandas as pd #lire et manipuler lesfichiers cvs\n",
    "import numpy as np #calcul numerique\n",
    "import os #chemin au datasets\n",
    "from datetime import datetime, timedelta \n",
    "\n",
    "#2) chargement des datasets nettoyes\n",
    "#definition du chemin depuis le notebook vers le dossier contenant les datasets\n",
    "data_path = os.path.join(\"..\", \"datasets\") #\"..\" pour remonter au dossier parent\n",
    "\n",
    "# chargement des fichiers nettoyees\n",
    "account_df = pd.read_csv(os.path.join(data_path, \"account_cleaned.csv\"))\n",
    "user_df = pd.read_csv(os.path.join(data_path, \"user_cleaned.csv\"))\n",
    "history_df = pd.read_csv(os.path.join(data_path, \"history_cleaned.csv\"))\n",
    "bill_df = pd.read_csv(os.path.join(data_path, \"bill_cleaned.csv\"))\n",
    "transfert_df = pd.read_csv(os.path.join(data_path, \"transfert_cleaned.csv\"))\n",
    "splogin_history_df = pd.read_csv(os.path.join(data_path, \"splogin_cleaned.csv\"))\n",
    "changes_df = pd.read_csv(os.path.join(data_path, \"changes_cleaned.csv\"))\n",
    "proceed_df = pd.read_csv(os.path.join(data_path, \"proceed_cleaned.csv\"))\n",
    "\n",
    "print(\"\\n Tous les fichiers CSV nettoyes ont été chargés avec succès !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b03029a2-959d-405d-bc8d-ab497b8cd3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des features extraites de history_cleaned.csv :\n",
      "    user_id  hour  day_of_week  is_weekend  balance_variation\n",
      "0  0.000735     0            3           0          -0.000141\n",
      "1  0.000735     0            3           0          -0.000141\n",
      "2  0.000735     0            3           0          -0.000141\n",
      "3  0.000735     0            3           0          -0.000141\n",
      "4  0.000735     0            3           0          -0.000141\n"
     ]
    }
   ],
   "source": [
    "#3) extraction des caracteristiques par classe\n",
    "\n",
    "#a) classe history\n",
    "\n",
    "# S'assurer que la colonne 'date' est bien de type datetime\n",
    "history_df['date'] = pd.to_datetime(history_df['date'])\n",
    "\n",
    "# Créer un nouveau DataFrame pour stocker uniquement les features extraites\n",
    "history_features = pd.DataFrame()\n",
    "\n",
    "# Clé de jointure pour la fusion future\n",
    "history_features['user_id'] = history_df['user_id']\n",
    "\n",
    "# 1. Heure de la transaction (0 à 23)\n",
    "history_features['hour'] = history_df['date'].dt.hour\n",
    "\n",
    "# 2. Jour de la semaine (0 = lundi, 6 = dimanche)\n",
    "history_features['day_of_week'] = history_df['date'].dt.dayofweek\n",
    "\n",
    "# 3. Indicateur si la transaction a eu lieu un week-end (1 = oui, 0 = non)\n",
    "history_features['is_weekend'] = history_features['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "# 4. Variation de solde autour de la transaction\n",
    "# Cela permet de voir si une transaction a eu un impact inhabituel\n",
    "history_features['balance_variation'] = (\n",
    "    history_df['current_account_balance'] - history_df['prev_account_balance']\n",
    ")\n",
    "\n",
    "# 5. [Optionnel] Encodage du statut s'il est présent (FAILED, SUCCESS, etc.)\n",
    "# if 'status' in history_df.columns:\n",
    "#     history_features['status_failed'] = (history_df['status'] == 'FAILED').astype(int)\n",
    "\n",
    "# 6. [Optionnel] Encodage des frais si la colonne existe\n",
    "# if 'transaction_fees' in history_df.columns:\n",
    "#     history_features['transaction_fees_anomalous'] = history_df['transaction_fees'].apply(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "# Afficher les premières lignes pour vérification\n",
    "print(\"Aperçu des features extraites de history_cleaned.csv :\")\n",
    "print(history_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c1013e6-9a31-4299-9930-6af10dd6c77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des features extraites de user_cleaned.csv :\n",
      "    user_id  account_age_days  is_verified_user  location_variation  \\\n",
      "0  0.000000             20198               0.0                   1   \n",
      "1  0.001827             20198               0.0                   1   \n",
      "2  0.002558             20198               0.0                   1   \n",
      "3  0.004750             20198               0.0                   1   \n",
      "4  0.005115             20198               1.0                   1   \n",
      "\n",
      "   host_location_incoherent  transaction_count  \n",
      "0                         1           0.000000  \n",
      "1                         1           0.000340  \n",
      "2                         1           0.003574  \n",
      "3                         1           0.139113  \n",
      "4                         1           0.024760  \n"
     ]
    }
   ],
   "source": [
    "# b. classe user\n",
    "\n",
    "# Vérifier que les colonnes de date sont bien au format datetime\n",
    "user_df['date_start'] = pd.to_datetime(user_df['date_start'])\n",
    "\n",
    "# Créer un DataFrame pour stocker uniquement les features\n",
    "user_features = pd.DataFrame()\n",
    "\n",
    "# Clé d'identification principale\n",
    "user_features['user_id'] = user_df['id']  # id de l'utilisateur (clé primaire)\n",
    "\n",
    "# 1. Ancienneté du compte (en jours)\n",
    "user_features['account_age_days'] = (pd.Timestamp.now() - user_df['date_start']).dt.days\n",
    "\n",
    "# 2. Vérification du compte (1 = vérifié, 0 = non vérifié)\n",
    "# Utiliser la bonne colonne selon le nom trouvé précédemment\n",
    "user_features['is_verified_user'] = user_df['verif_user_1']\n",
    "\n",
    "# 3. Variation de localisation (ville actuelle vs dernière connue)\n",
    "user_features['location_variation'] = (user_df['host_city'] != user_df['last_host_location']).astype(int)\n",
    "\n",
    "# 4. Incohérence géographique (même logique que location_variation)\n",
    "user_features['host_location_incoherent'] = (user_df['host_city'] != user_df['last_host_location']).astype(int)\n",
    "\n",
    "# 5. [Optionnel] Score utilisateur si disponible\n",
    "if 'score' in user_df.columns:\n",
    "    user_features['user_score'] = user_df['score']\n",
    "\n",
    "# 6. [Optionnel] Nombre de transactions (utile pour identifier les profils dormants)\n",
    "if 'nb_trans' in user_df.columns:\n",
    "    user_features['transaction_count'] = user_df['nb_trans']\n",
    "\n",
    "# Affichage pour vérification\n",
    "print(\"Aperçu des features extraites de user_cleaned.csv :\")\n",
    "print(user_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "265ac1be-aef4-43e1-a4c3-84a7c94ced14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des features extraites de proceed_cleaned.csv :\n",
      "   user_id  proceed_amount  currency_CDF  currency_DOGE  currency_LTC  \\\n",
      "0      0.0    2.000000e-16           0.0            0.0           0.0   \n",
      "1      0.0    2.000000e-14           0.0            0.0           0.0   \n",
      "2      0.0    5.000000e-15           0.0            0.0           0.0   \n",
      "3      0.0    5.000000e-15           0.0            0.0           0.0   \n",
      "4      0.0    5.000000e-15           0.0            0.0           0.0   \n",
      "\n",
      "   currency_USD  currency_XAF  currency_XOF  wallet_known_user  service_id  \n",
      "0           1.0           0.0           0.0                  1    0.035714  \n",
      "1           0.0           1.0           0.0                  1    0.000000  \n",
      "2           0.0           1.0           0.0                  1    0.000000  \n",
      "3           0.0           1.0           0.0                  1    0.000000  \n",
      "4           0.0           1.0           0.0                  1    0.000000  \n"
     ]
    }
   ],
   "source": [
    "# c. classe proceed\n",
    "\n",
    "# Création du DataFrame des features\n",
    "proceed_features = pd.DataFrame()\n",
    "\n",
    "# Clé de liaison pour les futures fusions\n",
    "proceed_features['user_id'] = proceed_df['user_id']\n",
    "\n",
    "# 1. Montant traité par la transaction (utile pour évaluer les anomalies de volume)\n",
    "proceed_features['proceed_amount'] = proceed_df['amount']\n",
    "\n",
    "# 2. Devise utilisée \n",
    "#. Encodage des devises déjà présent (on copie directement les colonnes)\n",
    "currency_columns = [col for col in proceed_df.columns if col.startswith(\"currency_\")]\n",
    "proceed_features = pd.concat([proceed_features, proceed_df[currency_columns]], axis=1)\n",
    "\n",
    "# 3. Indicateur : le wallet utilisé est-il connu ou non (NULL = suspect)\n",
    "proceed_features['wallet_known_user'] = proceed_df['wallet'].notnull().astype(int)\n",
    "\n",
    "# 4. [Optionnel] Service utilisé si colonne présente\n",
    "if 'service_id' in proceed_df.columns:\n",
    "    proceed_features['service_id'] = proceed_df['service_id']\n",
    "\n",
    "# 5. [Optionnel] Type d’opération si présent\n",
    "if 'operation_id' in proceed_df.columns:\n",
    "    proceed_features['operation_id'] = proceed_df['operation_id']\n",
    "\n",
    "# Affichage d’un aperçu des features extraites\n",
    "print(\"Aperçu des features extraites de proceed_cleaned.csv :\")\n",
    "print(proceed_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93c59ea6-f072-46df-91ba-2d6774ad0348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des features extraites de splogin_cleaned.csv :\n",
      "    user_id  total_logins  login_successes  login_failures  failure_ratio  \\\n",
      "0  0.005952            35              2.0            33.0       0.942857   \n",
      "1  0.005952            35              2.0            33.0       0.942857   \n",
      "2  0.006410           145              0.0           145.0       1.000000   \n",
      "3  0.006410           145              0.0           145.0       1.000000   \n",
      "4  0.006410           145              0.0           145.0       1.000000   \n",
      "\n",
      "   unique_countries  unique_cities  \n",
      "0                 2              7  \n",
      "1                 2              7  \n",
      "2                 3             10  \n",
      "3                 3             10  \n",
      "4                 3             10  \n"
     ]
    }
   ],
   "source": [
    "# d. classe splogin_history\n",
    "\n",
    "\n",
    "# === Étape 1 : Création du DataFrame des features ===\n",
    "splogin_features = pd.DataFrame()\n",
    "\n",
    "# Clé pour relier avec les autres sources\n",
    "splogin_features[\"user_id\"] = splogin_history_df[\"user_id\"]\n",
    "\n",
    "# 1. Nombre total de tentatives de connexion par utilisateur\n",
    "login_counts = splogin_history_df.groupby(\"user_id\").size()\n",
    "splogin_features[\"total_logins\"] = splogin_features[\"user_id\"].map(login_counts)\n",
    "\n",
    "# 2. Nombre de connexions réussies (status_SUCCESS = 1)\n",
    "splogin_features[\"login_successes\"] = splogin_history_df.groupby(\"user_id\")[\"status_SUCCESS\"].transform(\"sum\")\n",
    "\n",
    "# 3. Nombre d'échecs = total - succès\n",
    "splogin_features[\"login_failures\"] = splogin_features[\"total_logins\"] - splogin_features[\"login_successes\"]\n",
    "\n",
    "# 4. Ratio de connexions échouées\n",
    "splogin_features[\"failure_ratio\"] = (\n",
    "    splogin_features[\"login_failures\"] / splogin_features[\"total_logins\"]\n",
    ").fillna(0)\n",
    "\n",
    "# 5. Nombre de pays différents utilisés pour se connecter\n",
    "country_counts = splogin_history_df.groupby(\"user_id\")[\"country\"].nunique()\n",
    "splogin_features[\"unique_countries\"] = splogin_features[\"user_id\"].map(country_counts)\n",
    "\n",
    "# 6. Nombre de villes différentes utilisées\n",
    "city_counts = splogin_history_df.groupby(\"user_id\")[\"city\"].nunique()\n",
    "splogin_features[\"unique_cities\"] = splogin_features[\"user_id\"].map(city_counts)\n",
    "\n",
    "# === Étape 4 : Aperçu final ===\n",
    "print(\"Aperçu des features extraites de splogin_cleaned.csv :\")\n",
    "print(splogin_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8909fd8-fe23-43ba-9193-0aef1e7bdf15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id        jour  nb_paiements_par_jour  montant_total_par_jour\n",
      "0  0.00000  2021-11-18                      4                3.999999\n",
      "1  0.00294  2021-07-14                      3                2.999999\n",
      "2  0.00294  2021-07-18                      1                1.000000\n",
      "3  0.00294  2021-07-22                      1                1.000000\n",
      "4  0.00294  2021-07-24                      1                1.000000\n"
     ]
    }
   ],
   "source": [
    "# e. classe bill\n",
    "# Objectif : connaître l’activité de paiement de chaque utilisateur\n",
    "\n",
    "# 1. Convertir la colonne 'proceed_at' en format datetime\n",
    "# Si certaines dates sont mal formatées, elles deviendront NaT (Not a Time)\n",
    "bill_df['proceed_at'] = pd.to_datetime(bill_df['proceed_at'], errors='coerce')\n",
    "\n",
    "# 2. Supprimer les lignes où la date est invalide\n",
    "bill_df = bill_df.dropna(subset=['proceed_at'])\n",
    "\n",
    "# 3. Extraire uniquement la date (sans l’heure) pour grouper par jour\n",
    "bill_df['jour'] = bill_df['proceed_at'].dt.date\n",
    "\n",
    "# 4. Grouper par utilisateur et jour pour obtenir :\n",
    "#    - le nombre de paiements effectués dans la journée\n",
    "#    - le montant total payé cette journée\n",
    "bill_features = bill_df.groupby(['user_id', 'jour']).agg(\n",
    "    nb_paiements_par_jour=('amount', 'count'),\n",
    "    montant_total_par_jour=('amount', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# 9. Afficher ou sauvegarder le résultat\n",
    "print(bill_features.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be6f1795-241d-4590-9a3c-5ecc1a0d0c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des caractéristiques extraites de changes_cleaned.csv :\n",
      "     user_id  total_in_amount  total_out_amount  nb_changes_transactions  \\\n",
      "0   0.000369         0.000003      1.753777e-06                        8   \n",
      "1   0.000738         0.000051      4.090962e-05                        6   \n",
      "9   0.000000         0.000136      2.396141e-04                       26   \n",
      "13  0.152768         0.000008      1.368489e-08                        1   \n",
      "19  0.148339         0.000002      9.756839e-06                        9   \n",
      "\n",
      "    avg_in_amount  avg_out_amount  in_out_ratio  nb_success_changes  \\\n",
      "0    3.378889e-07    2.192221e-07      1.541308                 5.0   \n",
      "1    8.450967e-06    6.818270e-06      1.239459                 6.0   \n",
      "9    5.232670e-06    9.215927e-06      0.567786                24.0   \n",
      "13   7.613354e-06    1.368489e-08    556.332959                 1.0   \n",
      "19   2.468652e-07    1.084093e-06      0.227716                 2.0   \n",
      "\n",
      "    success_rate_changes  \n",
      "0               0.625000  \n",
      "1               1.000000  \n",
      "9               0.923077  \n",
      "13              1.000000  \n",
      "19              0.222222  \n"
     ]
    }
   ],
   "source": [
    "# f.classe changes\n",
    "\n",
    "# === Vérification si 'proceed_at' est bien une date ===\n",
    "if 'proceed_at' in changes_df.columns:\n",
    "    changes_df[\"proceed_at\"] = pd.to_datetime(changes_df[\"proceed_at\"], errors='coerce')\n",
    "\n",
    "# === Création du DataFrame des features ===\n",
    "changes_features = pd.DataFrame()\n",
    "\n",
    "# 1. Identifiant utilisateur\n",
    "if \"user_id\" in changes_df.columns:\n",
    "    changes_features[\"user_id\"] = changes_df[\"user_id\"]\n",
    "else:\n",
    "    print(\"Attention : colonne 'user_id' absente du fichier changes_cleaned.csv\")\n",
    "\n",
    "# 2. Montant total reçu (in_amount)\n",
    "if \"in_amount\" in changes_df.columns:\n",
    "    changes_features[\"total_in_amount\"] = changes_df.groupby(\"user_id\")[\"in_amount\"].transform(\"sum\")\n",
    "\n",
    "# 3. Montant total envoyé (out_amount)\n",
    "if \"out_amount\" in changes_df.columns:\n",
    "    changes_features[\"total_out_amount\"] = changes_df.groupby(\"user_id\")[\"out_amount\"].transform(\"sum\")\n",
    "\n",
    "# 4. Nombre total de transactions effectuées\n",
    "changes_features[\"nb_changes_transactions\"] = changes_df.groupby(\"user_id\")[\"id\"].transform(\"count\")\n",
    "\n",
    "# 5. Moyenne des montants envoyés et reçus\n",
    "changes_features[\"avg_in_amount\"] = changes_df.groupby(\"user_id\")[\"in_amount\"].transform(\"mean\")\n",
    "changes_features[\"avg_out_amount\"] = changes_df.groupby(\"user_id\")[\"out_amount\"].transform(\"mean\")\n",
    "\n",
    "# 6. Ratio in/out (attention aux divisions par zéro)\n",
    "changes_features[\"in_out_ratio\"] = (\n",
    "    changes_features[\"total_in_amount\"] / changes_features[\"total_out_amount\"]\n",
    ").replace([float(\"inf\"), -float(\"inf\")], 0).fillna(0)\n",
    "\n",
    "# 7. Nombre de statuts SUCCESS (si one-hot encoding est déjà appliqué)\n",
    "if \"status_SUCCESS\" in changes_df.columns:\n",
    "    changes_features[\"nb_success_changes\"] = changes_df.groupby(\"user_id\")[\"status_SUCCESS\"].transform(\"sum\")\n",
    "    \n",
    "    # Ratio de succès\n",
    "    changes_features[\"success_rate_changes\"] = (\n",
    "        changes_features[\"nb_success_changes\"] / changes_features[\"nb_changes_transactions\"]\n",
    "    ).fillna(0)\n",
    "\n",
    "# Supprimer les doublons dus au groupby\n",
    "changes_features = changes_features.drop_duplicates(subset=[\"user_id\"])\n",
    "\n",
    "# === Aperçu final ===\n",
    "print(\"Aperçu des caractéristiques extraites de changes_cleaned.csv :\")\n",
    "print(changes_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e8835ed-942e-4f7e-9ca9-7800cd57d22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des caractéristiques extraites de account_cleaned.csv :\n",
      "     user_id  total_balance  avg_balance  nb_accounts  total_trade_balance  \\\n",
      "0   0.000732       0.754910     0.188727            4             2.816901   \n",
      "4   0.002928       1.554216     0.194277            8             5.646313   \n",
      "9   0.003294       1.511367     0.188921            8             5.633806   \n",
      "13  0.003660       1.554380     0.194298            8             5.636632   \n",
      "17  0.004026       0.754910     0.188727            4             2.816901   \n",
      "\n",
      "    days_since_last_update  \n",
      "0                    20198  \n",
      "4                    20198  \n",
      "9                    20198  \n",
      "13                   20198  \n",
      "17                   20198  \n"
     ]
    }
   ],
   "source": [
    "# f. classe account\n",
    "\n",
    "# === Création du DataFrame des features ===\n",
    "account_features = pd.DataFrame()\n",
    "\n",
    "# 1. Clé utilisateur\n",
    "if \"user_id\" in account_df.columns:\n",
    "    account_features[\"user_id\"] = account_df[\"user_id\"]\n",
    "else:\n",
    "    print(\"Attention : colonne 'user_id' absente dans account_cleaned.csv\")\n",
    "\n",
    "# 2. Solde total des comptes par utilisateur\n",
    "if \"balance\" in account_df.columns:\n",
    "    account_features[\"total_balance\"] = account_df.groupby(\"user_id\")[\"balance\"].transform(\"sum\")\n",
    "\n",
    "# 3. Solde moyen des comptes\n",
    "account_features[\"avg_balance\"] = account_df.groupby(\"user_id\")[\"balance\"].transform(\"mean\")\n",
    "\n",
    "# 4. Nombre de comptes possédés\n",
    "account_features[\"nb_accounts\"] = account_df.groupby(\"user_id\")[\"wallet\"].transform(\"count\")\n",
    "\n",
    "# 5. Somme du solde en attente (pending_balance)\n",
    "if \"pending_balance\" in account_df.columns:\n",
    "    account_features[\"total_pending_balance\"] = account_df.groupby(\"user_id\")[\"pending_balance\"].transform(\"sum\")\n",
    "\n",
    "# 6. Somme du trade_balance si disponible\n",
    "if \"trade_balance\" in account_df.columns:\n",
    "    account_features[\"total_trade_balance\"] = account_df.groupby(\"user_id\")[\"trade_balance\"].transform(\"sum\")\n",
    "\n",
    "# 7. Dernière mise à jour (peut être utile pour détecter des comptes dormants)\n",
    "if \"updated_at\" in account_df.columns:\n",
    "    account_df[\"updated_at\"] = pd.to_datetime(account_df[\"updated_at\"], errors=\"coerce\")\n",
    "    last_update = account_df.groupby(\"user_id\")[\"updated_at\"].transform(\"max\")\n",
    "    account_features[\"days_since_last_update\"] = (pd.Timestamp.now() - last_update).dt.days\n",
    "\n",
    "# Supprimer les doublons dus aux .transform\n",
    "account_features = account_features.drop_duplicates(subset=[\"user_id\"])\n",
    "\n",
    "# === Aperçu final ===\n",
    "print(\"Aperçu des caractéristiques extraites de account_cleaned.csv :\")\n",
    "print(account_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9ed5e43-0b40-40ea-88ff-5eaaeb6bc7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fusion des features\n",
    "\n",
    "# Renommer la colonne 'id' en 'user_id' pour permettre la fusion cohérente avec les autres fichiers\n",
    "user_df = user_df.rename(columns={\"id\": \"user_id\"})\n",
    "\n",
    "# Fonction utilitaire pour éviter les colonnes dupliquées\n",
    "def safe_merge(df1, df2, on=\"user_id\"):\n",
    "    # Identifier les colonnes communes hors clé de jointure\n",
    "    common_cols = [col for col in df1.columns if col in df2.columns and col != on]\n",
    "    # Supprimer les colonnes dupliquées du second DataFrame\n",
    "    df2_cleaned = df2.drop(columns=common_cols)\n",
    "    # Effectuer la fusion (jointure gauche)\n",
    "    return df1.merge(df2_cleaned, on=on, how=\"left\")\n",
    "\n",
    "# Initialiser le DataFrame final avec les données utilisateurs\n",
    "merged_features = user_df.copy()\n",
    "\n",
    "# Fusion successive avec toutes les autres tables nettoyées\n",
    "merged_features = safe_merge(merged_features, history_df)\n",
    "merged_features = safe_merge(merged_features, proceed_df)\n",
    "merged_features = safe_merge(merged_features, splogin_history_df)\n",
    "merged_features = safe_merge(merged_features, bill_df)\n",
    "merged_features = safe_merge(merged_features, changes_df)\n",
    "merged_features = safe_merge(merged_features, account_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd831a56-0485-4775-95b9-7d6c7691a69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id                    float64\n",
      "username                   float64\n",
      "date_start          datetime64[ns]\n",
      "last_operation             float64\n",
      "balance                    float64\n",
      "                         ...      \n",
      "currency_id_7.0            float64\n",
      "currency_id_8.0            float64\n",
      "currency_id_14.0           float64\n",
      "currency_id_15.0           float64\n",
      "currency_id_21.0           float64\n",
      "Length: 90, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>date_start</th>\n",
       "      <th>last_operation</th>\n",
       "      <th>balance</th>\n",
       "      <th>nb_trans</th>\n",
       "      <th>contact</th>\n",
       "      <th>rewards_balance</th>\n",
       "      <th>matricule</th>\n",
       "      <th>last_login</th>\n",
       "      <th>...</th>\n",
       "      <th>trade_balance</th>\n",
       "      <th>currency_id_2.0</th>\n",
       "      <th>currency_id_3.0</th>\n",
       "      <th>currency_id_4.0</th>\n",
       "      <th>currency_id_5.0</th>\n",
       "      <th>currency_id_7.0</th>\n",
       "      <th>currency_id_8.0</th>\n",
       "      <th>currency_id_14.0</th>\n",
       "      <th>currency_id_15.0</th>\n",
       "      <th>currency_id_21.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>0.199932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>0.199932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>0.199932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>0.199932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>0.199932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  username date_start  last_operation   balance  nb_trans   contact  \\\n",
       "0      0.0  0.001494 1970-01-01        0.855809  0.199932       0.0  0.000374   \n",
       "1      0.0  0.001494 1970-01-01        0.855809  0.199932       0.0  0.000374   \n",
       "2      0.0  0.001494 1970-01-01        0.855809  0.199932       0.0  0.000374   \n",
       "3      0.0  0.001494 1970-01-01        0.855809  0.199932       0.0  0.000374   \n",
       "4      0.0  0.001494 1970-01-01        0.855809  0.199932       0.0  0.000374   \n",
       "\n",
       "   rewards_balance  matricule  last_login  ...  trade_balance  \\\n",
       "0              1.0   0.000374    0.000374  ...       0.704225   \n",
       "1              1.0   0.000374    0.000374  ...       0.704225   \n",
       "2              1.0   0.000374    0.000374  ...       0.704225   \n",
       "3              1.0   0.000374    0.000374  ...       0.704225   \n",
       "4              1.0   0.000374    0.000374  ...       0.704225   \n",
       "\n",
       "   currency_id_2.0  currency_id_3.0  currency_id_4.0  currency_id_5.0  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   currency_id_7.0  currency_id_8.0  currency_id_14.0  currency_id_15.0  \\\n",
       "0              0.0              0.0               0.0               0.0   \n",
       "1              0.0              0.0               0.0               0.0   \n",
       "2              0.0              0.0               0.0               0.0   \n",
       "3              0.0              0.0               0.0               0.0   \n",
       "4              0.0              0.0               0.0               0.0   \n",
       "\n",
       "   currency_id_21.0  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) NETTOYAGE FINAL\n",
    "\n",
    "# Nettoyage final\n",
    "\n",
    "# 1. Remplacer les NaN uniquement dans les colonnes numériques par 0\n",
    "numeric_cols = merged_features.select_dtypes(include=['float64', 'int64']).columns\n",
    "merged_features[numeric_cols] = merged_features[numeric_cols].fillna(0)\n",
    "\n",
    "# 2. Vérifier les types de colonnes après remplacement\n",
    "print(merged_features.dtypes)\n",
    "\n",
    "# 3. Afficher un aperçu des premières lignes\n",
    "merged_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f35209cb-c2d4-493f-8a7b-0ddd6b916f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sauvegardées avec succès dans : ..\\features\\features_transactions.csv\n"
     ]
    }
   ],
   "source": [
    "# Définir le chemin vers le dossier \"features\"\n",
    "merged_path = os.path.join(\"..\", \"features\")\n",
    "\n",
    "# 2. Définir le nom complet du fichier\n",
    "merged_file = os.path.join(merged_path, \"features_transactions.csv\")\n",
    "\n",
    "# 3. Sauvegarder le fichier CSV\n",
    "merged_features.to_csv(merged_file, index=False)\n",
    "\n",
    "print(f\"Features sauvegardées avec succès dans : {merged_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb9335-fdde-416e-a261-437883d057c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
